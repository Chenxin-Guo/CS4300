{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Game of Thrones (Extra Credit)\n",
    "## Â© Cristian Danescu-Niculescu-Mizil 2020\n",
    "## CS/INFO 4300 Language and Information\n",
    "## Due by midnight on Wednesday February 12th\n",
    "\n",
    "This assignment is **individual**.\n",
    "\n",
    "By now, you've had some exposure to techniques for uncovering social dynamics in textual data through your assignments working with the \"Keeping Up With The Kardashians\" data set.\n",
    "\n",
    "In this assignment we will be giving you the freedom to conduct analysis **of your choosing** on transcripts from the television series \"A Game of Thrones\".\n",
    "\n",
    "**Extra Credit Policy**\n",
    "\n",
    "The policy for this extra credit is that you should complete as much as you can.\n",
    "\n",
    "\n",
    "**Learning Objectives**\n",
    "\n",
    "This project aims to help you get comfortable working with the following tools / technologies / concepts:\n",
    "\n",
    "* Applying learned tools to conduct novel analysis\n",
    "\n",
    "**Academic Integrity and Collaboration**\n",
    "\n",
    "Note that these projects should be completed individually. As a result, all University-standard academic integrity guidelines must be followed.\n",
    "\n",
    "**Grading**\n",
    "\n",
    "This extra credit assignment is open-ended and will ask you to do a free-form analysis.\n",
    "The number of extra points will be decided based on how interesting, creative and unique your analysis is.  This will be in part a subjective judgement on the part of the TAs.\n",
    "\n",
    "\n",
    "**Submission**\n",
    "\n",
    "You are expected to submit this .ipynb as your submission for Assignment 2 Extra Credit. \n",
    "\n",
    "In addition please submit an html copy of the notebook (You can create this by clicking File > Download as > HTML (.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Ensure that your kernel is using Python3\n",
    "assert sys.version_info.major == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free-form Analysis\n",
    "\n",
    "## Preprocessing\n",
    "\n",
    "We have provided you with some pre-cleansed data that contains a subset of the \"Game Of Thrones\" transcripts. This is by no means a comprehensive data set (many episodes are not represented), but it should be enough data for you to make some meaningful observations. \n",
    "\n",
    "The data is represented as a dictionary that maps an episode title to a transcript (represented as a list of speaker-line tuples):\n",
    "```\n",
    "{'A Golden Crown': [\n",
    "      ('EDDARD', '  Your pardon, your Grace.'),\n",
    "      ('CERSEI', ' Do you know what your wife has done?'),\n",
    "      ...\n",
    "    ],\n",
    "  ...\n",
    "}\n",
    "```\n",
    "\n",
    "**However, the data is messy so you might want to do some additional steps to clean it.**\n",
    "\n",
    "e.g. Character names may not be consistent throughout the transcripts. There might be spelling errors in the names, and characters may be referenced by their first name only or by their full name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"GoT_transcripts_c.p\", \"rb\") as file:\n",
    "    got_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit Task\n",
    "For extra credit, we would like you to attempt the **ONE** of the following tasks:\n",
    "\n",
    "## OPTION 1 :\n",
    "1. Explore the role of gender in social interactions. For example, do people of one gender talk differently to those of the opposite gender? You should base this analysis on the age-based social interaction analysis in Assignment 2. You might also consider comparing GoT results with Kardashians results.\n",
    "2. Provide at least 1 plot illustrating your results.\n",
    "\n",
    "**NOTE:** Being that there are many characters in GoT, you may have to select a subset of the characters to work with and look up their genders. If you are looking only at a subset of the characters, please provide an explanation as for how and why you arrived at the subset that you did.\n",
    "\n",
    "\n",
    "## OPTION 2 :\n",
    "1. Propose an interesting question that you would like to explore in regard to the GoT dataset. \n",
    "2. Answer your question by conducting and documenting your analysis on the dataset.\n",
    "3. Provide at least 1 plot illustrating your results\n",
    "\n",
    "\n",
    "**NOTE**: You will be rewarded points based on novelty of question and on the thoughtfulness of the exploration.\n",
    "\n",
    "Make sure you clearly express the questions you are asking, and document the code. \n",
    "Try to use the level of detail we used in our problems from A2.   \n",
    "Also, interpret the results (highlighting what you found particularly interesting/unexpected). \n",
    "\n",
    "You may import additional libraries as you see fit so long as they are standard python libraries (https://docs.python.org/3/library/) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have also provided you with a few helper functions to aid you in your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"Returns a list of tokens from an input string.\n",
    "    \n",
    "    Params: {text: string}\n",
    "    Returns: List\n",
    "    \"\"\"\n",
    "    return [x for x in re.findall(r\"[a-z]*\", text.lower()) if x != \"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTION 2 :\n",
    "### Question:  find the least frequent words, and figure out who speak these words most frequently and who speak these words least frequently.###\n",
    "**Note: Build a n_good_names by n_good_words matrix, with matrix[i,j] be the number of times this words speaked by person i. **\n",
    "\n",
    "In order to de-emphasize the ratios of rare words (i.e. words in rare contexts are more likely to occur for only a single pair), we will apply additive smoothing also known as Laplace smoothing. This means that we will add one to each character-pair word occurrence before reweighting.\n",
    "\n",
    "So, for a given word $w$, person $p$, amd character-pair word occurrence $\\text{count}(p, w)$, the weighted occurrence $W(p, w)$ is\n",
    "\n",
    "$$ W(p, w) = \\frac{\\text{count}(p, w) + 1}{\\displaystyle\\sum_{\\pi \\in \\text{good person}} \\big(\\text{count}(\\pi, w) + 1\\big)} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANALYSIS HERE\n",
    "from nltk.corpus import stopwords \n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "value = list(got_data.values())\n",
    "word_tokens = []\n",
    "for epi in value:\n",
    "    for sent in epi:\n",
    "        word_tokens += [w.lower() for w in tokenize(sent[1])]\n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "from collections import Counter\n",
    "word_dic = Counter(filtered_sentence)\n",
    "sort_word = sorted(word_dic.items(),key=lambda x:x[1])\n",
    "word_list = [w for (w,k) in sort_word]\n",
    "word_index_reverse = {j: i for (i,j) in enumerate(word_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TYRION', 'JON', 'EDDARD', 'CERSEI', 'DAENERYS', 'JAIME', 'ARYA', 'LITTLEFINGER', 'CATELYN', 'SANSA', 'ROBB', 'ROBERT', 'NED', 'JORAH', 'SAM', 'BRAN', 'BRONN']\n",
      "{'TYRION': 0, 'JON': 1, 'EDDARD': 2, 'CERSEI': 3, 'DAENERYS': 4, 'JAIME': 5, 'ARYA': 6, 'LITTLEFINGER': 7, 'CATELYN': 8, 'SANSA': 9, 'ROBB': 10, 'ROBERT': 11, 'NED': 12, 'JORAH': 13, 'SAM': 14, 'BRAN': 15, 'BRONN': 16}\n"
     ]
    }
   ],
   "source": [
    "name_list = []\n",
    "for epi in value:\n",
    "    for sent in epi:\n",
    "        name_list.append(sent[0])\n",
    "name_counter = Counter(name_list)\n",
    "#Create good_name_list for top 17 frequent name appear in the episodes: that is the name that appears at least 100 times\n",
    "good_name_list = [w for (w,k) in sorted(name_counter.items(),key=lambda x:x[1], reverse = True)][:17]\n",
    "print(good_name_list)\n",
    "good_name_index_reverse = {j: i for (i,j) in enumerate(good_name_list)}\n",
    "print(good_name_index_reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ..., 45., 19., 11.])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_good_names = len(good_name_list)\n",
    "n_good_words =  len(word_list)\n",
    "words_matrix = np.zeros((n_good_names, n_good_words))\n",
    "for epi in got_data.values():\n",
    "    for sent in epi:\n",
    "        name = sent[0]\n",
    "        words = tokenize(sent[1])\n",
    "        for w in words:\n",
    "            if (w.lower() in word_list) & (name in good_name_list):\n",
    "                words_matrix[good_name_index_reverse[name], word_index_reverse[w.lower()]] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a weighted words matrix\n",
    "weighted_words_dup = np.copy(words_matrix)\n",
    "weighted_words_dup = (weighted_words_dup+1)/(np.sum(weighted_words_dup, axis =0)+weighted_words_dup.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.73856209 5.79411765 5.73856209 5.73856209 6.46078431 5.73856209\n",
      " 5.96078431 6.29411765 5.8496732  5.73856209 6.07189542 5.73856209\n",
      " 5.73856209 6.01633987 5.73856209 5.90522876 5.73856209]\n",
      "[ 0 14 12 11  9 16  3  2  5  1  8 15  6 13 10  7  4]\n",
      "DAENERYS\n",
      "LITTLEFINGER\n",
      "ROBB\n",
      "JORAH\n",
      "ARYA\n",
      "BRAN\n",
      "CATELYN\n",
      "JON\n",
      "JAIME\n",
      "EDDARD\n",
      "CERSEI\n",
      "BRONN\n",
      "SANSA\n",
      "ROBERT\n",
      "NED\n",
      "SAM\n",
      "TYRION\n"
     ]
    }
   ],
   "source": [
    "words_frequency_ratio_sum = np.sum(weighted_words_dup[:, :100], axis = 1)\n",
    "words_frequency_ratio_sum_sorted_index = np.argsort(words_frequency_ratio_sum)\n",
    "print(words_frequency_ratio_sum)\n",
    "print(words_frequency_ratio_sum_sorted_index)\n",
    "# find the name of these people:\n",
    "for i in words_frequency_ratio_sum_sorted_index[::-1]:\n",
    "    print(good_name_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the word_list is created with sequence that from least frequent to most frequent, i choose top 100 least frequent words and take the sum of all weighted appearance ratios.\n",
    "\n",
    "From the words_frequency_ratio_sum, we find there is not significant difference between people saying top 100 least frequent words. most of ratios are between 5.6 to 6.0. There are only 4 people who say a bit more least frequency words in the transcripts.\n",
    "\n",
    "They are \n",
    "DAENERYS,\n",
    "LITTLEFINGER,\n",
    "ROBB,\n",
    "JORAH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
